{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBwPbSa4XCARRQOFh4NyMi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grifire/tp-rag-student-version/blob/main/rendu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Vérifie si le code est exécuté sur Google Colab\n",
        "if 'COLAB_GPU' in os.environ:\n",
        "    # Commandes à exécuter uniquement sur Google Colab\n",
        "    !git clone https://github.com/grifire/tp-rag-student-version.git\n",
        "    %cd tp-rag-student-version\n",
        "    !pip install -r requirement.txt\n",
        "else:\n",
        "    # Commandes à exécuter si ce n'est pas sur Google Colab\n",
        "    print(\"Pas sur Google Colab, ces commandes ne seront pas exécutées.\")"
      ],
      "metadata": {
        "id": "jsGxBHNkPNwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Etape 1. - Indexation des documents"
      ],
      "metadata": {
        "id": "1bgTU0zTV-CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-huggingface"
      ],
      "metadata": {
        "id": "I4Y-0XXMXjzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\")"
      ],
      "metadata": {
        "id": "_ls830-UWGGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm -rf chroma_langchain_db\n"
      ],
      "metadata": {
        "id": "kaVsUdAotwyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-chroma"
      ],
      "metadata": {
        "id": "z7V6evV9XR7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
        ")"
      ],
      "metadata": {
        "id": "Oi2NPM1YXJh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-community pypdf pillow"
      ],
      "metadata": {
        "id": "DmsVd7mMaYYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 1 Indexation"
      ],
      "metadata": {
        "id": "6DBNAsvDybcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader(\"data/\")\n",
        "#loader2 (txt)\n",
        "#loader3 (latex)\n",
        "docs = loader.load() # + loarder2.load() + loader3.load()\n",
        "\n",
        "print(f\"number of documents: {len(docs)}\")\n",
        "# assert len(docs) == 1\n",
        "print(f\"Total characters: {len(docs[0].page_content)}\")"
      ],
      "metadata": {
        "id": "q_u3NKl_u7Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # chunk size (characters)\n",
        "    chunk_overlap=200,  # chunk overlap (characters)\n",
        "    add_start_index=True,  # track index in original document\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
      ],
      "metadata": {
        "id": "z4Ytr_OKxL6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ids = vector_store.add_documents(documents=all_splits)\n",
        "\n",
        "print(document_ids[:3])"
      ],
      "metadata": {
        "id": "ju3EYNXVxOZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "7acX3grW0AjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 2 Interrogation"
      ],
      "metadata": {
        "id": "aHzJIa5bygZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query: str):\n",
        "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
        "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
        "    serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "    )\n",
        "    return serialized, retrieved_docs"
      ],
      "metadata": {
        "id": "socICxMByTB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_query = retrieve_context('Attention is all you need')\n",
        "print(f\"Résultat : {res_query}\")"
      ],
      "metadata": {
        "id": "rxukY53q0Glb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context_score(query: str):\n",
        "  retrieved_docs = []\n",
        "  scores = []\n",
        "  for res, score in vector_store.similarity_search_with_relevance_scores(\"Attention is all you need\", k=2) :\n",
        "    retrieved_docs.append(res)\n",
        "    scores.append(score)\n",
        "  serialized = \"\\n\\n\".join(\n",
        "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
        "        for doc in retrieved_docs\n",
        "  )\n",
        "  return serialized, retrieved_docs, scores\n",
        "#print(score)\n",
        "\n",
        "# for doc, score in res:\n",
        "#     print(doc.metadata)\n",
        "#     print(score)"
      ],
      "metadata": {
        "id": "FwlMnAPb4Ph8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_query_score = retrieve_context_score('Attention is all you need')\n",
        "for i in range(len(res_query_score[1])) :\n",
        "  print(f\"Score de {res_query_score[2][i]} :\\n{res_query_score[1][i]}\\n\\n\")\n",
        ""
      ],
      "metadata": {
        "id": "_oKCoO3a9HcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Etape 2"
      ],
      "metadata": {
        "id": "sGJfjnPcK5Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 3"
      ],
      "metadata": {
        "id": "dgpohnsRLNCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "(\n",
        "  \"system\",\n",
        "  \"You are an experienced journalist. \"\n",
        "  \"Answer the user's question using ONLY the provided context. \"\n",
        "  \"Cite the relevant excerpts from the context in your answer.\"\n",
        "),\n",
        "(\n",
        "  \"human\",\n",
        "  \"Context:\\n{context}\\n\\nQuestion:\\n{question}\"\n",
        ")\n",
        "])"
      ],
      "metadata": {
        "id": "bmDOqy7fLRGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice 4"
      ],
      "metadata": {
        "id": "IaXxpZAPNTC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm\n",
        "%load_ext colabxterm\n",
        "%xterm"
      ],
      "metadata": {
        "id": "_gVbG31fNWIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-ollama"
      ],
      "metadata": {
        "id": "ktro_q8kPCZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=\"qwen3:8b\",\n",
        "    temperature=0,\n",
        ")"
      ],
      "metadata": {
        "id": "sH5CUjA1N07n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\n",
        "        \"system\",\n",
        "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
        "    ),\n",
        "    (\"human\", \"I love programming.\"),\n",
        "]\n",
        "ai_msg = llm.invoke(messages)\n",
        "ai_msg"
      ],
      "metadata": {
        "id": "8y3IgXPWQZu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PromptTemplate(retrieve, question, langue = \"french\"):\n",
        "  prompt = [\n",
        "      (\n",
        "          \"system\",\n",
        "          f\"You are a helpful assistant. Answer in the following language : {langue}\"\n",
        "      ),\n",
        "      (\n",
        "          \"human\",\n",
        "          f\"Context:\\n{retrieve(question)[0]}\\n\\nQuestion:\\n{question}\"\n",
        "      )\n",
        "  ]\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "nsxYGUgpRO0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PromptTemplate(retrieve_context_score,\"What is attention?\")"
      ],
      "metadata": {
        "id": "XJPhW1L1TZHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_message = llm.invoke(PromptTemplate(retrieve_context_score,\"What is the attention\"))\n",
        "ai_message"
      ],
      "metadata": {
        "id": "xUrLukDWTsjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modifié par gemini.Semble marcher mais a vérifier\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "\n",
        "llm_agent = ChatOllama(\n",
        "    model=\"qwen3:8b\",\n",
        "    temperature=0,\n",
        "    memory=InMemorySaver(),\n",
        ")\n",
        "\n",
        "llm_agent.invoke(\n",
        "    [{\"role\": \"user\", \"content\": \"Hi! My name is Bob.\"}] ,\n",
        "    config= {\"configurable\": {\"thread_id\": \"1\"}},\n",
        ")"
      ],
      "metadata": {
        "id": "u0RILlULbrkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-xzGTBMedds4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}